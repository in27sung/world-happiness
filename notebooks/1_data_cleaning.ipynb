{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ab126a-3aa2-4bb1-8762-f93cceb2dbf5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# World Happiness & Economic and social indicators correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84627cf6-3c4f-4832-9576-04912be4ac08",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e241308c-abeb-4cab-a7d9-9c5e267e23f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 2.2.3, numpy: 2.2.2, sklearn: 1.6.1, seaborn: 0.13.2\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import warnings\n",
    "\n",
    "# Version Check\n",
    "print(f\"pandas: {pd.__version__}, numpy: {np.__version__}, sklearn: {sklearn.__version__}, seaborn: {sns.__version__}\")\n",
    "\n",
    "# Warnings Off\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Load Datasets\n",
    "def load_dataset(path):\n",
    "    \"\"\"Load CSV dataset with standard parameters.\"\"\"\n",
    "    return pd.read_csv(path, encoding='utf-8-sig', skip_blank_lines=True)\n",
    "\n",
    "happiness_df = load_dataset('../data/raw/World_Happiness_Index_2015_2024.csv')\n",
    "gdp_df = load_dataset(\"../data/raw/GDP_per_capita_2015_2023.csv\")\n",
    "edu_df = load_dataset(\"../data/raw/Education_Attainment_Bachelor_2015_2023.csv\")\n",
    "life_exp_wb = load_dataset(\"../data/raw/WorldBank_Life_Expectancy_2015_2022.csv\")\n",
    "life_exp_2023 = load_dataset(\"../data/raw/OECD_Life_Expectancy_Total_2023_Cleaned.csv\")\n",
    "unemp_df = load_dataset(\"../data/raw/Unemployment_Rate_2015_2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0791100f-f219-4a28-ac0e-88220c19e56f",
   "metadata": {},
   "source": [
    "## Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "dad4703c-aa90-4a6f-ae72-2f596f04481e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Happiness Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>Finland</td>\n",
       "      <td>7.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2.523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year      Country  Happiness Score\n",
       "0  2024      Finland            7.736\n",
       "1  2023  Afghanistan            1.721\n",
       "2  2022  Afghanistan            1.859\n",
       "3  2021  Afghanistan            2.404\n",
       "4  2020  Afghanistan            2.523"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect data\n",
    "happiness_df.head()\n",
    "# gdp_df.head()\n",
    "# edu_df.head()\n",
    "# life_exp_wb.head()\n",
    "# life_exp_2023.head()\n",
    "# unemp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "2a8690d3-a88f-451c-b939-61998bbdab89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "2015    157\n",
       "2016    155\n",
       "2017    156\n",
       "2018    156\n",
       "2019    153\n",
       "2020    149\n",
       "2021    146\n",
       "2022    137\n",
       "2023    143\n",
       "2024    147\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness_df['Year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "4de27202-4106-4676-a040-5fc7c7346800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_df['Country Name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "557c7eff-9bb6-46ab-b2e6-41f04b5cfe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1499 entries, 0 to 1498\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Year             1499 non-null   int64  \n",
      " 1   Country          1499 non-null   object \n",
      " 2   Happiness Score  1499 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 35.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260 entries, 0 to 259\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Country Name  260 non-null    object \n",
      " 1   Country Code  260 non-null    object \n",
      " 2   2015          259 non-null    float64\n",
      " 3   2016          258 non-null    float64\n",
      " 4   2017          258 non-null    float64\n",
      " 5   2018          258 non-null    float64\n",
      " 6   2019          259 non-null    float64\n",
      " 7   2020          258 non-null    float64\n",
      " 8   2021          258 non-null    float64\n",
      " 9   2022          255 non-null    float64\n",
      " 10  2023          243 non-null    float64\n",
      "dtypes: float64(9), object(2)\n",
      "memory usage: 22.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 180 entries, 0 to 179\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Country Name  180 non-null    object \n",
      " 1   Country Code  180 non-null    object \n",
      " 2   2015          97 non-null     float64\n",
      " 3   2016          98 non-null     float64\n",
      " 4   2017          110 non-null    float64\n",
      " 5   2018          110 non-null    float64\n",
      " 6   2019          123 non-null    float64\n",
      " 7   2020          95 non-null     float64\n",
      " 8   2021          100 non-null    float64\n",
      " 9   2022          107 non-null    float64\n",
      " 10  2023          33 non-null     float64\n",
      "dtypes: float64(9), object(2)\n",
      "memory usage: 15.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 259 entries, 0 to 258\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Country Name  259 non-null    object \n",
      " 1   Country Code  259 non-null    object \n",
      " 2   2015          258 non-null    float64\n",
      " 3   2016          258 non-null    float64\n",
      " 4   2017          258 non-null    float64\n",
      " 5   2018          257 non-null    float64\n",
      " 6   2019          257 non-null    float64\n",
      " 7   2020          257 non-null    float64\n",
      " 8   2021          258 non-null    float64\n",
      " 9   2022          257 non-null    float64\n",
      " 10  2023          0 non-null      float64\n",
      "dtypes: float64(9), object(2)\n",
      "memory usage: 22.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28 entries, 0 to 27\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Country               28 non-null     object \n",
      " 1   Life Expectancy 2023  28 non-null     float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 576.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 235 entries, 0 to 234\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Country Name  235 non-null    object \n",
      " 1   Country Code  235 non-null    object \n",
      " 2   2015          235 non-null    float64\n",
      " 3   2016          235 non-null    float64\n",
      " 4   2017          235 non-null    float64\n",
      " 5   2018          235 non-null    float64\n",
      " 6   2019          235 non-null    float64\n",
      " 7   2020          235 non-null    float64\n",
      " 8   2021          235 non-null    float64\n",
      " 9   2022          234 non-null    float64\n",
      " 10  2023          232 non-null    float64\n",
      "dtypes: float64(9), object(2)\n",
      "memory usage: 20.3+ KB\n"
     ]
    }
   ],
   "source": [
    "happiness_df.info()\n",
    "gdp_df.info()\n",
    "edu_df.info()\n",
    "life_exp_wb.info()\n",
    "life_exp_2023.info()\n",
    "unemp_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d8bcc-9377-43d2-9aa4-fee5c0e48a83",
   "metadata": {},
   "source": [
    "## Initial Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111133e1-66a6-44f0-b587-659bc238555e",
   "metadata": {},
   "source": [
    "### Data Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d505abd4-7603-4b5b-9f67-ac1fcfb94595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Wide to Long format\n",
    "def wide_to_long(df, value_name):\n",
    "    \"\"\"Convert wide format to long format.\"\"\"\n",
    "    \n",
    "    # Standardise column names\n",
    "    if 'Country Name' in df.columns:\n",
    "        df = df.rename(columns={'Country Name': 'Country'})\n",
    "    \n",
    "    # Exclude 'Country Code' if present\n",
    "    id_vars = ['Country']\n",
    "    if 'Country Code' in df.columns:\n",
    "        id_vars.append('Country Code')\n",
    "    \n",
    "    df_long = df.melt(id_vars=id_vars, var_name='Year', value_name=value_name)\n",
    "    \n",
    "    # Drop 'Country Code' after melt\n",
    "    if 'Country Code' in df_long.columns:\n",
    "        df_long = df_long.drop(columns=['Country Code'])\n",
    "    \n",
    "    # Convert year to int (skip invalid rows safely)\n",
    "    df_long = df_long[df_long['Year'].str.isnumeric()]\n",
    "    df_long['Year'] = df_long['Year'].astype(int)\n",
    "    \n",
    "    return df_long\n",
    "\n",
    "# Apply conversion\n",
    "gdp_long = wide_to_long(gdp_df, 'GDP_per_capita')\n",
    "edu_long = wide_to_long(edu_df, 'Education_Attainment')\n",
    "life_exp_wb_long = wide_to_long(life_exp_wb, 'Life_Expectancy')\n",
    "unemp_long = wide_to_long(unemp_df, 'Unemployment_Rate')\n",
    "\n",
    "# OECD life expectancy is already long format, just rename columns\n",
    "life_exp_oecd_long = life_exp_2023.rename(columns={'Life Expectancy 2023': 'Life_Expectancy', 'Country': 'Country'})\n",
    "life_exp_oecd_long['Year'] = 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8495ed-40e9-4a17-8fdf-fbe179be7cb4",
   "metadata": {},
   "source": [
    "### Section Subtitle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a967b3fc-9b85-4418-a4f8-4018c50420a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define country name standardisation function\n",
    "def standardise_country_column(df):\n",
    "    \"\"\"\n",
    "    Standardise 'Country' column: lowercasing and stripping whitespace.\n",
    "    \"\"\"\n",
    "    df['Country'] = df['Country'].str.strip().str.lower()\n",
    "    return df\n",
    "\n",
    "# Apply to all long datasets\n",
    "for df in [happiness_df, gdp_long, edu_long, life_exp_wb_long, life_exp_oecd_long, unemp_long]:\n",
    "    standardise_country_column(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f77f39-ec6e-4d79-ac0c-757b59753340",
   "metadata": {},
   "source": [
    "###  Removing Non-Country Entries for Dataset Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "df993796-cc7c-43fb-8ad4-7460e145142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed non-country entries: 42 entries removed from GDP. Remaining: 218 countries.\n",
      "Removed non-country entries: 1 entries removed from Education. Remaining: 179 countries.\n",
      "Removed non-country entries: 42 entries removed from Life Exp WB. Remaining: 217 countries.\n",
      "Removed non-country entries: 0 entries removed from Life Exp OECD. Remaining: 28 countries.\n",
      "Removed non-country entries: 42 entries removed from Unemployment. Remaining: 193 countries.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define Function to Identify Group/Region Names\n",
    "def is_group(name):\n",
    "    patterns = [\n",
    "        'income', 'region', 'area', 'ida', 'ibrd', 'small states', 'world', 'union',\n",
    "        'total', 'blend', 'dividend', 'members', 'arab world', 'latin america',\n",
    "        'sub-saharan', 'europe & central asia', 'pacific island', 'fragile', 'oecd',\n",
    "        'post-demographic', 'pre-demographic', 'middle east', 'caribbean', 'heavily indebted'\n",
    "    ]\n",
    "    for p in patterns:\n",
    "        if re.search(p, str(name).lower()):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Standardised Filtering Function\n",
    "def filter_out_groups(df, df_name):\n",
    "    before = df['Country'].nunique()\n",
    "    df = df[~df['Country'].apply(is_group)]\n",
    "    after = df['Country'].nunique()\n",
    "    print(f\"Removed non-country entries: {before - after} entries removed from {df_name}. Remaining: {after} countries.\")\n",
    "    return df\n",
    "\n",
    "# Apply to all datasets\n",
    "gdp_long = filter_out_groups(gdp_long, 'GDP')\n",
    "edu_long = filter_out_groups(edu_long, 'Education')\n",
    "life_exp_wb_long = filter_out_groups(life_exp_wb_long, 'Life Exp WB')\n",
    "life_exp_oecd_long = filter_out_groups(life_exp_oecd_long, 'Life Exp OECD')\n",
    "unemp_long = filter_out_groups(unemp_long, 'Unemployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f78d6-7745-4c1c-ab13-6c9026b025c1",
   "metadata": {},
   "source": [
    "### Checking Country Mismatches Against 2024 Target Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "39dc5120-6be5-48f1-8560-3705e1189da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDP mismatched countries (88): ['africa eastern and southern', 'africa western and central', 'american samoa', 'andorra', 'angola', 'antigua and barbuda', 'aruba', 'bahamas, the', 'barbados', 'belarus', 'bermuda', 'bhutan', 'brunei darussalam', 'burundi', 'cabo verde', 'cayman islands', 'central african republic', 'central europe and the baltics', 'channel islands', 'congo, dem. rep.', 'congo, rep.', \"cote d'ivoire\", 'cuba', 'curacao', 'djibouti', 'dominica', 'east asia & pacific', 'egypt, arab rep.', 'equatorial guinea', 'faroe islands', 'fiji', 'french polynesia', 'gambia, the', 'greenland', 'grenada', 'guam', 'guinea-bissau', 'guyana', 'haiti', 'hong kong sar, china', 'iran, islamic rep.', 'isle of man', 'kiribati', 'korea, rep.', 'kyrgyz republic', 'least developed countries: un classification', 'liechtenstein', 'macao sar, china', 'maldives', 'marshall islands', 'micronesia, fed. sts.', 'moldova', 'monaco', 'nauru', 'new caledonia', 'north america', 'northern mariana islands', 'palau', 'papua new guinea', 'puerto rico', 'qatar', 'rwanda', 'samoa', 'san marino', 'sao tome and principe', 'seychelles', 'sint maarten (dutch part)', 'slovak republic', 'solomon islands', 'south asia', 'south sudan', 'st. kitts and nevis', 'st. lucia', 'st. martin (french part)', 'st. vincent and the grenadines', 'sudan', 'suriname', 'syrian arab republic', 'timor-leste', 'tonga', 'turkiye', 'turkmenistan', 'turks and caicos islands', 'tuvalu', 'vanuatu', 'virgin islands (u.s.)', 'west bank and gaza', 'yemen, rep.']\n",
      "\n",
      "Education mismatched countries (56): ['andorra', 'angola', 'antigua and barbuda', 'belarus', 'bermuda', 'bhutan', 'brunei darussalam', 'burundi', 'cabo verde', 'cayman islands', 'central african republic', 'congo, dem. rep.', 'congo, rep.', \"cote d'ivoire\", 'cuba', 'curacao', 'djibouti', 'dominica', 'egypt, arab rep.', 'fiji', 'gambia, the', 'grenada', 'guinea-bissau', 'guyana', 'haiti', 'iran, islamic rep.', 'kiribati', \"korea, dem. people's rep.\", 'korea, rep.', 'kyrgyz republic', 'maldives', 'marshall islands', 'moldova', 'monaco', 'nauru', 'new caledonia', 'palau', 'papua new guinea', 'puerto rico', 'qatar', 'rwanda', 'samoa', 'san marino', 'sao tome and principe', 'slovak republic', 'sudan', 'suriname', 'timor-leste', 'tonga', 'turkiye', 'turkmenistan', 'turks and caicos islands', 'tuvalu', 'vanuatu', 'venezuela, rb', 'west bank and gaza']\n",
      "\n",
      "Life Exp WB mismatched countries (87): ['africa eastern and southern', 'africa western and central', 'angola', 'antigua and barbuda', 'aruba', 'bahamas, the', 'barbados', 'belarus', 'bermuda', 'bhutan', 'british virgin islands', 'brunei darussalam', 'burundi', 'cabo verde', 'cayman islands', 'central african republic', 'central europe and the baltics', 'channel islands', 'congo, dem. rep.', 'congo, rep.', \"cote d'ivoire\", 'cuba', 'curacao', 'djibouti', 'dominica', 'east asia & pacific', 'egypt, arab rep.', 'equatorial guinea', 'eritrea', 'faroe islands', 'fiji', 'french polynesia', 'gambia, the', 'gibraltar', 'greenland', 'grenada', 'guam', 'guinea-bissau', 'guyana', 'haiti', 'hong kong sar, china', 'iran, islamic rep.', 'isle of man', 'kiribati', \"korea, dem. people's rep.\", 'korea, rep.', 'kyrgyz republic', 'least developed countries: un classification', 'liechtenstein', 'macao sar, china', 'maldives', 'marshall islands', 'micronesia, fed. sts.', 'moldova', 'nauru', 'new caledonia', 'north america', 'papua new guinea', 'puerto rico', 'qatar', 'rwanda', 'samoa', 'sao tome and principe', 'seychelles', 'sint maarten (dutch part)', 'slovak republic', 'solomon islands', 'south asia', 'south sudan', 'st. kitts and nevis', 'st. lucia', 'st. martin (french part)', 'st. vincent and the grenadines', 'sudan', 'suriname', 'syrian arab republic', 'timor-leste', 'tonga', 'turkiye', 'turkmenistan', 'turks and caicos islands', 'tuvalu', 'vanuatu', 'venezuela, rb', 'virgin islands (u.s.)', 'west bank and gaza', 'yemen, rep.']\n",
      "\n",
      "Life Exp OECD mismatched countries (1): ['slovak republic']\n",
      "\n",
      "Unemployment mismatched countries (64): ['africa eastern and southern', 'africa western and central', 'angola', 'bahamas, the', 'barbados', 'belarus', 'bhutan', 'brunei darussalam', 'burundi', 'cabo verde', 'central african republic', 'central europe and the baltics', 'channel islands', 'congo, dem. rep.', 'congo, rep.', \"cote d'ivoire\", 'cuba', 'djibouti', 'east asia & pacific', 'egypt, arab rep.', 'equatorial guinea', 'eritrea', 'fiji', 'french polynesia', 'gambia, the', 'guam', 'guinea-bissau', 'guyana', 'haiti', 'hong kong sar, china', 'iran, islamic rep.', \"korea, dem. people's rep.\", 'korea, rep.', 'kyrgyz republic', 'least developed countries: un classification', 'macao sar, china', 'maldives', 'moldova', 'new caledonia', 'north america', 'papua new guinea', 'puerto rico', 'qatar', 'rwanda', 'samoa', 'sao tome and principe', 'slovak republic', 'solomon islands', 'south asia', 'south sudan', 'st. lucia', 'st. vincent and the grenadines', 'sudan', 'suriname', 'syrian arab republic', 'timor-leste', 'tonga', 'turkiye', 'turkmenistan', 'vanuatu', 'venezuela, rb', 'virgin islands (u.s.)', 'west bank and gaza', 'yemen, rep.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract 2024 Test Set Countries\n",
    "target_countries = set(happiness_df[happiness_df['Year'] == 2024]['Country'].unique())\n",
    "\n",
    "# Identify unmatched countries in each dataset\n",
    "def check_country_mismatch(df, name):\n",
    "    mismatch = set(df['Country'].unique()) - target_countries\n",
    "    print(f\"{name} mismatched countries ({len(mismatch)}): {sorted(mismatch)}\\n\")\n",
    "\n",
    "# Apply check to long format datasets\n",
    "check_country_mismatch(gdp_long, 'GDP')\n",
    "check_country_mismatch(edu_long, 'Education')\n",
    "check_country_mismatch(life_exp_wb_long, 'Life Exp WB')\n",
    "check_country_mismatch(life_exp_oecd_long, 'Life Exp OECD')\n",
    "check_country_mismatch(unemp_long, 'Unemployment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "901e6fc8-a940-4185-b217-e09446ae50c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries in Happiness 2024 but missing in Unemployment Dataset: 18\n",
      "['congo', 'c√¥te d‚Äôivoire', 'dr congo', 'egypt', 'gambia', 'hong kong sar of china', 'iran', 'kosovo', 'kyrgyzstan', 'republic of korea', 'republic of moldova', 'slovakia', 'state of palestine', 'taiwan province of china', 'trinidad and tobago', 't√ºrkiye', 'venezuela', 'yemen']\n"
     ]
    }
   ],
   "source": [
    "# Extract Country sets from each dataset\n",
    "gdp_countries = set(gdp_long['Country'].unique())\n",
    "edu_countries = set(edu_long['Country'].unique())\n",
    "life_exp_wb_countries = set(life_exp_wb_long['Country'].unique())\n",
    "life_exp_oecd_countries = set(life_exp_oecd_long['Country'].unique())\n",
    "unemp_countries = set(unemp_long['Country'].unique())\n",
    "\n",
    "# Identify countries present in Happiness 2024 but missing in Unemployment dataset\n",
    "missing_countries = target_countries - unemp_countries\n",
    "print(f\"Countries in Happiness 2024 but missing in Unemployment Dataset: {len(missing_countries)}\")\n",
    "print(sorted(missing_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "cc8e6ecb-d9df-4a8d-a11d-20d0f5c49bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Possible Matches in Unemployment Dataset:\n",
      "gambia ‚Üî Closest Match: ('gambia, the', 90)\n",
      "republic of korea ‚Üî Closest Match: ('korea, rep.', 86)\n",
      "trinidad and tobago ‚Üî Closest Match: ('st. vincent and the grenadines', 86)\n",
      "taiwan province of china ‚Üî Closest Match: ('china', 90)\n",
      "egypt ‚Üî Closest Match: ('egypt, arab rep.', 90)\n",
      "t√ºrkiye ‚Üî Closest Match: ('turkiye', 92)\n",
      "yemen ‚Üî Closest Match: ('yemen, rep.', 90)\n",
      "republic of moldova ‚Üî Closest Match: ('moldova', 90)\n",
      "kyrgyzstan ‚Üî Closest Match: ('kazakhstan', 60)\n",
      "slovakia ‚Üî Closest Match: ('slovenia', 75)\n",
      "kosovo ‚Üî Closest Match: ('lesotho', 46)\n",
      "iran ‚Üî Closest Match: ('iran, islamic rep.', 90)\n",
      "venezuela ‚Üî Closest Match: ('venezuela, rb', 95)\n",
      "c√¥te d‚Äôivoire ‚Üî Closest Match: (\"cote d'ivoire\", 96)\n",
      "hong kong sar of china ‚Üî Closest Match: ('hong kong sar, china', 95)\n",
      "congo ‚Üî Closest Match: ('congo, rep.', 90)\n",
      "state of palestine ‚Üî Closest Match: ('eswatini', 64)\n",
      "dr congo ‚Üî Closest Match: ('congo, dem. rep.', 86)\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "print(\"\\nPossible Matches in Unemployment Dataset:\")\n",
    "for country in missing_countries:\n",
    "    match = process.extractOne(country, list(unemp_countries))\n",
    "    print(f\"{country} ‚Üî Closest Match: {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e39698-4ce5-42c9-8570-81d27feef849",
   "metadata": {},
   "source": [
    "### Standardising Country Names Across Datasets for Reliable Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "349d3b18-6347-4b86-8380-fe118fe567c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mapping = {\n",
    "    'yemen': 'yemen, rep.',\n",
    "    'syria': 'syrian arab republic',\n",
    "    'republic of moldova': 'moldova',\n",
    "    'egypt': 'egypt, arab rep.',\n",
    "    'hong kong sar of china': 'hong kong sar, china',\n",
    "    'macedonia': 'north macedonia',\n",
    "    'congo': 'congo, dem. rep.',\n",
    "    'iran': 'iran, islamic rep.',\n",
    "    't√ºrkiye': 'turkiye',\n",
    "    'gambia': 'gambia, the',\n",
    "    'dr congo': 'congo, dem. rep.',\n",
    "    'c√¥te d‚Äôivoire': \"cote d'ivoire\",\n",
    "    'north cyprus': 'cyprus',\n",
    "    'republic of korea': 'korea, rep.',\n",
    "    'venezuela': 'venezuela, rb',\n",
    "    'swaziland': 'eswatini',\n",
    "    'kyrgyzstan': 'kyrgyz republic',\n",
    "    'slovakia': 'slovak republic',\n",
    "    'taiwan province of china': 'taiwan',\n",
    "}\n",
    "\n",
    "# Apply mapping to long format datasets\n",
    "for df in [happiness_df, gdp_long, edu_long, life_exp_wb_long, life_exp_oecd_long, unemp_long]:\n",
    "    df['Country'] = df['Country'].replace(country_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "89e93bba-89bb-4a67-bd28-101ab111d379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GDP] Missing countries after mapping: 17\n",
      "['congo', 'c√¥te d‚Äôivoire', 'dr congo', 'egypt', 'gambia', 'hong kong sar of china', 'iran', 'kyrgyzstan', 'republic of korea', 'republic of moldova', 'slovakia', 'state of palestine', 'taiwan province of china', 'trinidad and tobago', 't√ºrkiye', 'venezuela', 'yemen']\n",
      "[Education] Missing countries after mapping: 24\n",
      "['argentina', 'congo', 'c√¥te d‚Äôivoire', 'dr congo', 'egypt', 'gabon', 'gambia', 'hong kong sar of china', 'iran', 'kosovo', 'kyrgyzstan', 'libya', 'morocco', 'peru', 'republic of korea', 'republic of moldova', 'slovakia', 'state of palestine', 'taiwan province of china', 'trinidad and tobago', 't√ºrkiye', 'ukraine', 'venezuela', 'yemen']\n",
      "[Life Exp WB] Missing countries after mapping: 17\n",
      "['congo', 'c√¥te d‚Äôivoire', 'dr congo', 'egypt', 'gambia', 'hong kong sar of china', 'iran', 'kyrgyzstan', 'republic of korea', 'republic of moldova', 'slovakia', 'state of palestine', 'taiwan province of china', 'trinidad and tobago', 't√ºrkiye', 'venezuela', 'yemen']\n",
      "[Life Exp OECD] Missing countries after mapping: 120\n",
      "['afghanistan', 'albania', 'algeria', 'argentina', 'armenia', 'australia', 'azerbaijan', 'bahrain', 'bangladesh', 'belize', 'benin', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'burkina faso', 'cambodia', 'cameroon', 'canada', 'chad', 'china', 'colombia', 'comoros', 'congo', 'cyprus', 'c√¥te d‚Äôivoire', 'dominican republic', 'dr congo', 'ecuador', 'egypt', 'el salvador', 'eswatini', 'ethiopia', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'guatemala', 'guinea', 'honduras', 'hong kong sar of china', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kosovo', 'kuwait', 'kyrgyzstan', 'lao pdr', 'lebanon', 'lesotho', 'liberia', 'libya', 'madagascar', 'malawi', 'malaysia', 'mali', 'malta', 'mauritania', 'mauritius', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'paraguay', 'peru', 'philippines', 'republic of korea', 'republic of moldova', 'russian federation', 'saudi arabia', 'senegal', 'serbia', 'sierra leone', 'singapore', 'slovakia', 'somalia', 'south africa', 'sri lanka', 'state of palestine', 'taiwan province of china', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 't√ºrkiye', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'viet nam', 'yemen', 'zambia', 'zimbabwe']\n",
      "[Unemployment] Missing countries after mapping: 18\n",
      "['congo', 'c√¥te d‚Äôivoire', 'dr congo', 'egypt', 'gambia', 'hong kong sar of china', 'iran', 'kosovo', 'kyrgyzstan', 'republic of korea', 'republic of moldova', 'slovakia', 'state of palestine', 'taiwan province of china', 'trinidad and tobago', 't√ºrkiye', 'venezuela', 'yemen']\n"
     ]
    }
   ],
   "source": [
    "# Define function to check mismatch\n",
    "def check_mismatch(df, name):\n",
    "    df_countries = set(df['Country'].unique())\n",
    "    missing = target_countries - df_countries\n",
    "    print(f\"[{name}] Missing countries after mapping: {len(missing)}\")\n",
    "    print(sorted(missing))\n",
    "\n",
    "# Check for all datasets\n",
    "check_mismatch(gdp_long, 'GDP')\n",
    "check_mismatch(edu_long, 'Education')\n",
    "check_mismatch(life_exp_wb_long, 'Life Exp WB')\n",
    "check_mismatch(life_exp_oecd_long, 'Life Exp OECD')\n",
    "check_mismatch(unemp_long, 'Unemployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463d69f-5fbd-41a5-b8ec-796a73b6e601",
   "metadata": {},
   "source": [
    "### Country Alignment & Filtering Across Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c191e737-28fb-4a22-b354-3b97c8bd5f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Base: Total Happiness countries (2024): 147\n",
      "\n",
      "üîé GDP Dataset:\n",
      "- Total countries in dataset: 218\n",
      "- Common countries with Happiness 2024: 130\n",
      "- Countries in GDP but not in Happiness 2024: 88\n",
      "\n",
      "üîé Education Dataset:\n",
      "- Total countries in dataset: 179\n",
      "- Common countries with Happiness 2024: 123\n",
      "- Countries in Education but not in Happiness 2024: 56\n",
      "\n",
      "üîé Life Exp WB Dataset:\n",
      "- Total countries in dataset: 217\n",
      "- Common countries with Happiness 2024: 130\n",
      "- Countries in Life Exp WB but not in Happiness 2024: 87\n",
      "\n",
      "üîé Life Exp OECD Dataset:\n",
      "- Total countries in dataset: 28\n",
      "- Common countries with Happiness 2024: 27\n",
      "- Countries in Life Exp OECD but not in Happiness 2024: 1\n",
      "\n",
      "üîé Unemployment Dataset:\n",
      "- Total countries in dataset: 193\n",
      "- Common countries with Happiness 2024: 129\n",
      "- Countries in Unemployment but not in Happiness 2024: 64\n"
     ]
    }
   ],
   "source": [
    "# Store datasets\n",
    "datasets = {\n",
    "    'GDP': gdp_long,\n",
    "    'Education': edu_long,\n",
    "    'Life Exp WB': life_exp_wb_long,\n",
    "    'Life Exp OECD': life_exp_oecd_long,\n",
    "    'Unemployment': unemp_long\n",
    "}\n",
    "\n",
    "print(f\"üìä Base: Total Happiness countries (2024): {len(target_countries)}\")\n",
    "\n",
    "# Loop through datasets to calculate and display common and difference counts\n",
    "for name, df in datasets.items():\n",
    "    df_countries = set(df['Country'].unique())\n",
    "    common_countries = df_countries & target_countries\n",
    "    difference_countries = df_countries - target_countries\n",
    "    \n",
    "    print(f\"\\nüîé {name} Dataset:\")\n",
    "    print(f\"- Total countries in dataset: {len(df_countries)}\")\n",
    "    print(f\"- Common countries with Happiness 2024: {len(common_countries)}\")\n",
    "    print(f\"- Countries in {name} but not in Happiness 2024: {len(difference_countries)}\")\n",
    "    \n",
    "    # Filter the dataset to include only common countries\n",
    "    df_filtered = df[df['Country'].isin(target_countries)]\n",
    "    \n",
    "    # Update the dataset with the filtered data\n",
    "    datasets[name] = df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba201c5e-d4ff-4c0f-8c0c-d90f789b7db3",
   "metadata": {},
   "source": [
    "## Data Merging & Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e952c311-3bac-4195-8930-d74519abaebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All datasets saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory if not exists\n",
    "output_dir = '../data/processed/long'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Merge the life expectancy datasets (World Bank and OECD) on Country and Year\n",
    "life_exp_combined = pd.merge(\n",
    "    life_exp_wb_long[['Country', 'Year', 'Life_Expectancy']],\n",
    "    life_exp_oecd_long[['Country', 'Year', 'Life_Expectancy']],\n",
    "    on=['Country', 'Year'],\n",
    "    how='outer',\n",
    "    suffixes=('_WB', '_OECD')\n",
    ")\n",
    "\n",
    "# Combine values\n",
    "life_exp_combined['Life_Expectancy'] = life_exp_combined['Life_Expectancy_WB'].fillna(\n",
    "    life_exp_combined['Life_Expectancy_OECD']\n",
    ")\n",
    "life_exp_combined.drop(columns=['Life_Expectancy_WB', 'Life_Expectancy_OECD'], inplace=True)\n",
    "\n",
    "# Save cleaned long datasets\n",
    "gdp_long.to_csv(f'{output_dir}/gdp_long.csv', index=False)\n",
    "edu_long.to_csv(f'{output_dir}/edu_long.csv', index=False)\n",
    "unemp_long.to_csv(f'{output_dir}/unemp_long.csv', index=False)\n",
    "happiness_df.to_csv(f'{output_dir}/happiness_long.csv', index=False)\n",
    "life_exp_combined.to_csv(f'{output_dir}/life_exp_long.csv', index=False)\n",
    "print(\"‚úÖ All datasets saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "39b524fd-c60c-4f16-bded-3cd6b71cf078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Found 28 duplicate rows. Aggregating with mean...\n",
      "Merged dataset shape: (1217, 7)\n"
     ]
    }
   ],
   "source": [
    "# Merge datasets step by step\n",
    "merged_df = happiness_df.copy()\n",
    "\n",
    "# Sequentially merge\n",
    "merged_df = pd.merge(merged_df, gdp_long, on=['Country', 'Year'], how='inner')\n",
    "merged_df = pd.merge(merged_df, edu_long, on=['Country', 'Year'], how='inner')\n",
    "merged_df = pd.merge(merged_df, life_exp_combined, on=['Country', 'Year'], how='inner')\n",
    "merged_df = pd.merge(merged_df, unemp_long, on=['Country', 'Year'], how='inner')\n",
    "\n",
    "# Handle duplicates\n",
    "duplicates = merged_df[merged_df.duplicated(subset=['Country', 'Year'], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(f\"‚ö†Ô∏è Found {len(duplicates)} duplicate rows. Aggregating with mean...\")\n",
    "    merged_df = merged_df.groupby(['Country', 'Year'], as_index=False).mean(numeric_only=True)\n",
    "else:\n",
    "    print(\"‚úÖ No duplicate rows found.\")\n",
    "    \n",
    "print(f\"Merged dataset shape: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "c335f929-0fa3-444a-ac68-cff3f2d2e780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train and Test datasets saved!\n"
     ]
    }
   ],
   "source": [
    "# Filter for training set (exclude 2024)\n",
    "merged_df = merged_df[merged_df['Year'] < 2024].reset_index(drop=True)\n",
    "\n",
    "# Extract 2024 target dataset\n",
    "target_df = happiness_df[happiness_df['Year'] == 2024][['Year', 'Country', 'Happiness Score']]\n",
    "\n",
    "# Move label to last column\n",
    "merged_df = merged_df[[col for col in merged_df.columns if col != 'Happiness Score'] + ['Happiness Score']]\n",
    "target_df = target_df[[col for col in target_df.columns if col != 'Happiness Score'] + ['Happiness Score']]\n",
    "\n",
    "# Save datasets\n",
    "output_dir = '../data/processed/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "merged_df.to_csv(f'{output_dir}/merged_dataset.csv', index=False)\n",
    "target_df.to_csv(f'{output_dir}/target_dataset.csv', index=False)\n",
    "print(\"‚úÖ Train and Test datasets saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2c44a-255b-4692-a5f1-55a4e0ddc7b6",
   "metadata": {},
   "source": [
    "### Chat GPT Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3da01d-f73d-4384-89a1-7c43e0827b4f",
   "metadata": {},
   "source": [
    "This notebook summarises the data cleaning process applied to the original dataset. The goal was to prepare the data for analysis and modelling by handling missing values and ensuring consistency across key columns.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Column-Wise Cleaning Summary\n",
    "\n",
    "### 1. `Country`\n",
    "- **Transformation:** Converted all country names to Title Case.\n",
    "- **Reason:** For consistent formatting and better readability in visualisations and grouping operations.\n",
    "\n",
    "### 2. `Education_Attainment`\n",
    "- **Issue:** 462 missing values.\n",
    "- **Step 1:** Filled missing values using the **median within each country**.\n",
    "- **Step 2:** For countries where all values were missing (9 records), filled using the **overall median** of the dataset.\n",
    "- **Reason:** Median is robust to outliers and reflects typical values without being skewed. Country-specific median preserves local distribution.\n",
    "\n",
    "### 3. `Life_Expectancy`\n",
    "- **Issue:** 103 missing values.\n",
    "- **Step 1:** Applied **linear interpolation grouped by country** to fill time-series gaps.\n",
    "- **Step 2:** Remaining 101 missing values (from countries with no valid entries) were filled using the **global mean**.\n",
    "- **Reason:** Interpolation maintains temporal trends. For completely missing cases, the mean provides a stable fallback.\n",
    "\n",
    "### 4. `GDP_per_capita`, `Unemployment_Rate`, `Happiness Score`, `Year`\n",
    "- **Action:** No missing values; retained as-is.\n",
    "\n",
    "---\n",
    "\n",
    "## üóÇÔ∏è Output\n",
    "The cleaned dataset has been saved as:\n",
    "\n",
    "üìÅ `gpt_merged_dataset.csv`\n",
    "\n",
    "All columns are now fully complete with **no missing values** and ready for analysis or modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3c9971fa-3164-4980-b4f7-26163c85fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = load_dataset('../data/processed/gpt_merged_dataset.csv')\n",
    "\n",
    "# Split train, validation, test based on Year\n",
    "train = merged[merged['Year'] <= 2022]\n",
    "test  = merged[merged['Year'] == 2023]\n",
    "\n",
    "train.to_csv(f'../data/processed/gpt_train_dataset.csv', index=False)\n",
    "test.to_csv(f'../data/processed/gpt_test_dataset(2023).csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6829b86b-9425-4b96-a8f1-4a5dc364cf9b",
   "metadata": {},
   "source": [
    "## Post-EDA Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3079651d-6b43-4d4e-93c2-ed41b419b68a",
   "metadata": {},
   "source": [
    "### 1. time series-based interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "1ca01f43-ed28-4f2e-8e29-e3604de53a23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Interpolated dataset saved to: ../data/processed/merged_interpolated.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the merged dataset\n",
    "merged = pd.read_csv('../data/processed/merged_dataset_v1.1.csv')\n",
    "\n",
    "# Perform time series interpolation for each country\n",
    "for feature in ['Education_Attainment', 'Life_Expectancy']:\n",
    "    merged[feature] = (\n",
    "        merged.groupby('Country')[feature]\n",
    "        .transform(lambda x: x.interpolate(method='linear', limit_direction='both'))\n",
    "    )\n",
    "\n",
    "# Save the interpolated version\n",
    "output_path = '../data/processed/merged_interpolated.csv'\n",
    "merged.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Interpolated dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2108c3f1-4428-4424-ada2-3e7498bf318a",
   "metadata": {},
   "source": [
    "#### 1.1. Split train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "90a6e964-0d82-4ca8-823d-d46467991b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated = pd.read_csv('../data/processed/merged_interpolated.csv')\n",
    "\n",
    "# Split train, validation, test based on Year\n",
    "train = interpolated[interpolated['Year'] <= 2022]\n",
    "test  = interpolated[interpolated['Year'] == 2023]\n",
    "\n",
    "train.to_csv(f'../data/processed/train_dataset.csv', index=False)\n",
    "test.to_csv(f'../data/processed/test_dataset(2023).csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds_env)",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
